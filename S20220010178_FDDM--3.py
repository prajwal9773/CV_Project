# -*- coding: utf-8 -*-
"""S20220010178_FDDM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XGOZqTBqMuPIiFtSLdiU-j0iViiS8tYN
"""

!pip install opencv-python opencv-contrib-python

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Harris Corner Detection (using OpenCV)
def harris_corner_detection(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = np.float32(gray)
    dst = cv2.cornerHarris(gray, 2, 3, 0.04)
    dst = cv2.dilate(dst, None)
    img[dst > 0.01 * dst.max()] = [0, 0, 255]
    return img, dst

# Function to create Gaussian kernel
def create_gaussian_kernel(size, sigma=1.0):
    kernel = np.fromfunction(
        lambda x, y: (1 / (2 * np.pi * sigma ** 2)) * np.exp(
            - ((x - (size - 1) / 2) ** 2 + (y - (size - 1) / 2) ** 2) / (2 * sigma ** 2)),
        (size, size))
    return kernel / np.sum(kernel)

# Function to apply filter via convolution
def apply_filter(image, kernel):
    img_height, img_width = image.shape
    kernel_size = kernel.shape[0]
    pad = kernel_size // 2
    filtered_img = np.zeros_like(image, dtype=np.float32)
    padded_img = np.pad(image, ((pad, pad), (pad, pad)), mode='constant')

    for i in range(img_height):
        for j in range(img_width):
            region = padded_img[i:i + kernel_size, j:j + kernel_size]
            filtered_img[i, j] = np.sum(region * kernel)

    return np.clip(filtered_img, 0, 255).astype(np.uint8)

# Sobel Filter implementation
def sobel_filter(image):
    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
    sobel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])

    img_sobel_x = apply_filter(image, sobel_x)
    img_sobel_y = apply_filter(image, sobel_y)

    img_sobel_combined = np.sqrt(img_sobel_x**2 + img_sobel_y**2)
    return np.clip(img_sobel_combined, 0, 255).astype(np.uint8)

# Manual image rotation
def rotate_image(image, angle):
    angle_rad = np.radians(angle)
    cos_theta, sin_theta = np.cos(angle_rad), np.sin(angle_rad)
    height, width = image.shape[:2]

    new_width = int(np.abs(width * cos_theta) + np.abs(height * sin_theta))
    new_height = int(np.abs(width * sin_theta) + np.abs(height * cos_theta))

    rotated_img = np.zeros((new_height, new_width, 3), dtype=np.uint8)
    center_x, center_y = width // 2, height // 2
    new_center_x, new_center_y = new_width // 2, new_height // 2

    for i in range(new_height):
        for j in range(new_width):
            x = (j - new_center_x) * cos_theta + (i - new_center_y) * sin_theta + center_x
            y = -(j - new_center_x) * sin_theta + (i - new_center_y) * cos_theta + center_y

            if 0 <= int(y) < height and 0 <= int(x) < width:
                rotated_img[i, j] = image[int(y), int(x)]

    return rotated_img

# Function to detect and describe features using SIFT
def sift_feature_detection(gray):
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(gray, None)
    img_with_keypoints = cv2.drawKeypoints(gray, keypoints, None)
    return keypoints, descriptors, img_with_keypoints

# Function to match features using SSD and ratio test
def feature_matching(descriptors1, descriptors2, keypoints1, keypoints2, img1, img2):
    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)
    matches = bf.knnMatch(descriptors1, descriptors2, k=2)
    good_matches = []
    for m, n in matches:
        if m.distance < 0.75 * n.distance:
            good_matches.append(m)
    img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None)
    return img_matches

# Helper function to display images in Colab or locally
def show_image(img, title='Image'):
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

def heapify(arr, n, i):
    largest = i  # Initialize largest as root
    left = 2 * i + 1  # Left child index
    right = 2 * i + 2  # Right child index

    # If left child is larger than root
    if left < n and arr[left] > arr[largest]:
        largest = left

    # If right child is larger than largest so far
    if right < n and arr[right] > arr[largest]:
        largest = right

    # If largest is not root
    if largest != i:
        arr[i], arr[largest] = arr[largest], arr[i]  # Swap

        # Recursively heapify the affected sub-tree
        heapify(arr, n, largest)

def heap_sort(arr):
    n = len(arr)

    # Build a maxheap
    for i in range(n // 2 - 1, -1, -1):
        heapify(arr, n, i)

    # Extract elements one by one
    for i in range(n - 1, 0, -1):
        arr[i], arr[0] = arr[0], arr[i]  # Swap
        heapify(arr, i, 0)

def main():
    # Load the two images
    img1 = cv2.imread('img2.png')
    img2 = cv2.imread('img4.png')

    # Harris Corner Detection on the first image
    img1_harris, harris_response = harris_corner_detection(img1.copy())

    # Convert images to grayscale
    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian filter
    gaussian_kernel = create_gaussian_kernel(size=5, sigma=1.0)
    img1_gaussian = apply_filter(gray1, gaussian_kernel)
    img2_gaussian = apply_filter(gray2, gaussian_kernel)

    # Apply Sobel filter to detect edges
    img1_sobel = sobel_filter(gray1)
    img2_sobel = sobel_filter(gray2)

    # Rotate the images
    img1_rotated = rotate_image(img1, angle=45)
    img2_rotated = rotate_image(img2, angle=45)

    # Detect and describe features using SIFT
    keypoints1, descriptors1, img1_sift = sift_feature_detection(gray1)
    keypoints2, descriptors2, img2_sift = sift_feature_detection(gray2)

    # Feature matching using SSD and ratio distance
    img_matches = feature_matching(descriptors1, descriptors2, keypoints1, keypoints2, img1, img2)

    # Display results
    show_image(img1_harris, 'Harris Corners')
    show_image(img1_sift, 'SIFT Keypoints on Image 1')
    show_image(img2_sift, 'SIFT Keypoints on Image 2')
    show_image(img_matches, 'Feature Matches between Image 1 and Image 2')

if __name__ == "__main__":
    main()